{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97384152",
   "metadata": {},
   "source": [
    "# Criação do modelo de classificação para o chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05335cc6",
   "metadata": {},
   "source": [
    "## Importando os módulos necessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e60b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install --upgrade tensorflow_text\n",
    "!pip install --upgrade tensorflow_hub\n",
    "!pip install pandas\n",
    "!pip install tflearn\n",
    "!pip install sklearn\n",
    "!pip install numpy\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f7c1a",
   "metadata": {},
   "source": [
    "## Usando uma build pré-treinada e iniciando modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdff354",
   "metadata": {},
   "source": [
    "+ Usamos um modelo pré-treinado do Tensorflow Hub\n",
    "+ Usamos o pré-processador equivalente ao modelo escolhido\n",
    "+ Durante a execução, alguns warnings são exibidos. Isto se dá pela falta de uma GPU na máquina, então o aviso pode ser ignorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92d032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)\n",
    "bert_model = hub.KerasLayer(encoder_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4ec120",
   "metadata": {},
   "source": [
    "## Importando os dados para treinamento\n",
    "\n",
    "+ Os dados devem estar armazenados no mesmo diretório que o código\n",
    "+ Serão armazenados na forma de Dataframe, usando Pandas\n",
    "+ Após importação, é feita a transformação da variável categórica \"Tag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a6a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "df['funny'] = df['Tag'].apply(lambda x: 1 if x=='funny' else 0)\n",
    "df['goodbye'] = df['Tag'].apply(lambda x: 1 if x=='goodbye' else 0)\n",
    "df['greeting'] = df['Tag'].apply(lambda x: 1 if x=='greeting' else 0)\n",
    "df['me'] = df['Tag'].apply(lambda x: 1 if x=='me' else 0)\n",
    "df['query'] = df['Tag'].apply(lambda x: 1 if x=='query' else 0)\n",
    "df['thanks'] = df['Tag'].apply(lambda x: 1 if x=='thanks' else 0)\n",
    "df['use'] = df['Tag'].apply(lambda x: 1 if x=='use' else 0)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d328ce13",
   "metadata": {},
   "source": [
    "## Criação de dados de treinamento\n",
    "\n",
    "Nesta etapa, os dados salvos no dataframe são separados em duas partes:\n",
    "\n",
    "+ Uma lista de frases, seriam os dados de entrada\n",
    "+ Uma lista contendo a categoria (transformada em uma lista) equivalente a cada frase.\n",
    "\n",
    "Cada categoria é representada por uma lista de zeros contendo apenas um número um."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2229afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = df.values.tolist()\n",
    "intents = []\n",
    "sents = []\n",
    "for i in range(len(list)):\n",
    "    line = list[i][2:]\n",
    "    intents.append(line)\n",
    "    sents.append(list[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee21b43",
   "metadata": {},
   "source": [
    "## Criando o modelo\n",
    "\n",
    "+ A camada de input receberá um texto e passará adiante este texto pré-processado pelo modelo retirado do Tensorflow Hub\n",
    "+ Este texto pré-processado é processado pelas camadas do bert, modelo extraído do Tensorflow Hub\n",
    "+ Para evitar overfitting, foi adicionada uma camada de dropout\n",
    "+ Após o dropout, foi feita uma camada de classificação. Ela possui 6 neurônios, pois o sistema possui 6 classificações distintas. A função de ativação escolhida foi a softmax pois esta se sai melhor para tarefas de classificação com múltiplas categorias.\n",
    "+ O modelo é então criado com a arquitetura definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert layers\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "preprocessed_text = bert_preprocess_model(text_input)\n",
    "outputs = bert_model(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(outputs['pooled_output'])\n",
    "l = tf.keras.layers.Dense(7, activation='softmax', name=\"output\")(l)\n",
    "\n",
    "# Use inputs and outputs to construct a final model\n",
    "model = tf.keras.Model(inputs=[text_input], outputs = [l])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ed3618",
   "metadata": {},
   "source": [
    "## Definidas as métricas do modelo e feita a sua compilação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a32dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416e04df",
   "metadata": {},
   "source": [
    "## O modelo é então treinado\n",
    "\n",
    "+ Usa-se como conjunto de treinamento as frases retiradas do dataset\n",
    "+ Como trata-se de uma operação de aprendizagem supervisionada, as etiquetas para cada entrada são dadas pela categoria transformada anteriormente.\n",
    "+ usamos 1000 épocas e um tamanho de batch de 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46490b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(sents,intents,epochs=1000, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79907212",
   "metadata": {},
   "source": [
    "## O modelo é então salvo\n",
    "\n",
    "+ Foi utilizado o modelo no formato hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf257070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chatModel.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
